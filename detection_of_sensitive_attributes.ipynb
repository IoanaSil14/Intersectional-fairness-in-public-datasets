{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ba9531a6",
   "metadata": {},
   "source": [
    "# Semi-Automated Protected Attributes Detection through Sample/Label Biases\n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "id": "86a2c974",
   "metadata": {},
   "source": [
    "import math\n",
    "import itertools\n",
    "import fairlens as fl\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "#import quantecon as qe\n",
    "import statsmodels.api as sm\n",
    "\n",
    "from IPython.display import display\n",
    "\n",
    "from packages.imbalance_degree import imbalance_degree\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from aif360.datasets import BinaryLabelDataset\n",
    "from aif360.metrics import BinaryLabelDatasetMetric, ClassificationMetric\n",
    "\n",
    "from sklearn.datasets import fetch_openml\n",
    "from scipy.stats import entropy, pearsonr, chi2_contingency, pointbiserialr\n",
    "from statsmodels.stats.oneway import effectsize_oneway\n",
    "from statsmodels.formula.api import ols\n",
    "from scipy.stats.contingency import association\n",
    "from sklearn.preprocessing import MinMaxScaler, LabelEncoder\n",
    "from collections import Counter\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "8ce9c705",
   "metadata": {},
   "source": [
    "DATASETS = [\n",
    "    43141,   # ACS                                      JOB/INCOME\n",
    "    46356,   # German credit data                       FINANCE\n",
    "    45069,   # Diabetes                                 HEALTH\n",
    "    43904,   # Law                                      EDUCATION\n",
    " ]"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "04266e61",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "### Metrics Overview"
   ]
  },
  {
   "attachments": {
    "image-2.png": {
     "image/png": "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"
    },
    "image-3.png": {
     "image/png": "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"
    },
    "image-4.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "id": "ac66d966",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "**Entropy**\n",
    "\n",
    "Entropy is a metric often used in the context of information theory and machine learning to measure the impurity or disorder in a dataset. In classification tasks, entropy quantifies the uncertainty associated with class labels. It's commonly used to evaluate the effectiveness of splitting data based on a particular attribute.\n",
    "\n",
    "Reference to entropy metric and related equation:\n",
    "\n",
    "* https://ieeexplore.ieee.org/abstract/document/6773024\n",
    "\n",
    "Reference from **scipy.stats** [documentation](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.entropy.html):\n",
    "\n",
    "* Calculate the Shannon entropy/relative entropy of given distribution(s). <br>If only probabilities pk are given, the Shannon entropy is calculated as H = -sum(pk * log(pk)). By the default, log base is set to e (natural logarithm).\n",
    "\n",
    "Following entropy value interpretations are based from the book [Elements of information theory](https://eee.guc.edu.eg/Courses/Communications/COMM1003%20Information%20Theory/Solution_Manual.pdf) written by Cover, Thomas M., and Joy A. Thomas in 2006:\n",
    "\n",
    "* The values represent information entropy measured in nats (short for natural units of information), rather than bits (base 2 logarithmic scale).\n",
    "\n",
    "    * Range of Entropy Values (0 to 1):\n",
    "    \n",
    "        * In a natural logarithmic scale, entropy values typically range from 0 to 1 nats. An entropy of 0 nats indicates that the data source is completely predictable, with no uncertainty or randomness. This means one has perfect knowledge of the data. As entropy increases, it indicates increasing uncertainty and randomness in the data source. \n",
    "    \n",
    "    * Low Entropy (Close to 0 nats):\n",
    "        * When entropy is close to 0 nats, it means that the information source or dataset is highly ordered and predictable in a natural logarithmic context. For example, if one has a dataset of events that always occur in a consistent pattern, the entropy in nats would be close to 0.\n",
    "    \n",
    "    * Moderate Entropy (Between 0 and 1 nats):\n",
    "        * Entropy values between 0 and 1 nats represent varying degrees of uncertainty or randomness in a natural logarithmic context. For example, if one has a dataset of events that occur with some degree of unpredictability, the entropy in nats would be moderate.\n",
    "        \n",
    "     * High Entropy (Close to 1 nats):\n",
    "         * When entropy is close to 1 nats, it means that the information source or dataset is highly unpredictable and random in a natural logarithmic context. For example, if one has a dataset of events that occur randomly and with equal probability, the entropy in nats would be close to 1.\n",
    "\n",
    "<br>\n",
    "\n",
    "**Imbalance Ratio**\n",
    "\n",
    "Imbalance Ratio is a class-imbalance extent metric that considers both the class distribution and the dimensionality of an imbalanced dataset. It is the most commonly used measure to describe the imbalance extent of a dataset:\n",
    "\n",
    "![image-2.png](attachment:image-2.png)\n",
    "\n",
    "where N<sub>maj</sub> is the sample size of the majority class and N<sub>min</sub> is the sample size of the minority class. When there are multi-classes, i.e. the number of classes is larger than 2, N<sub>maj</sub> is the sample size of the largest majority class and N<sub>min</sub> is the sample size of the smallest minority class. It is clear that when IR = 1 , we have an exactly balanced dataset. When IR > 1, the larger the IR, the larger the imbalance extent of the dataset.\n",
    "\n",
    "Reference to imbalance ratio metric and related equation:\n",
    "\n",
    "* https://www.sciencedirect.com/science/article/abs/pii/S0167865520300829?casa_token=ZtBYgYHMwrkAAAAA:7ljNGyKBpRWzEf5byZCjAC4ovozrEfdR7z2SMngMjHYyf0pWtaMjllRjnTWxrgGudZ6j0e5jVvIg\n",
    "\n",
    "<br>\n",
    "\n",
    "**Imbalance Degree**\n",
    "\n",
    "The imbalance degree metric quantifies the extent of class imbalance in a multi-class or binary classification problem. It provides a single numerical value that represents the degree to which class distribution is skewed or imbalanced in the dataset. The metric is computed based on the proportions of instances belonging to different classes. A lower imbalance degree value suggests a more balanced distribution, while a higher value indicates a greater level of imbalance, where certain classes dominate the dataset in terms of representation.\n",
    "\n",
    "![image-3.png](attachment:image-3.png)\n",
    "\n",
    "Reference to imbalance degree metric and related equation:\n",
    "\n",
    "* https://www.sciencedirect.com/science/article/pii/S016786551730257X\n",
    "\n",
    "**Statistical Parity Difference**\n",
    "\n",
    "* Reference:\n",
    "    * [Garg, Pratyush, et al. \"Fairness metrics: A comparative analysis.\" 2020 IEEE, 2020.](https://ieeexplore.ieee.org/abstract/document/9378025?casa_token=imZhhCuHchAAAAAA:cvTOPdCJlBTyPABtIAARC6ll_tm1PtJpwkSK1LV9uvaZcMiGySAcAhq6Bfsf4qwtF7e3mgJlR9h8rA)\n",
    "\n",
    "        * The base rate of a group is the ratio of people in the group who belong to the positive class (y = 1) to the total number of people in that group. Thus, having non-equal base rates across groups means p(y = 1|G = 0) = p(y = 1|G = 1). This assumption is to ensure that the analysis reflects group imbalance, which is typically present in practice.\n",
    "    * [AIF 360 Documentation](https://aif360.readthedocs.io/en/stable/modules/generated/aif360.metrics.BinaryLabelDatasetMetric.html#aif360.metrics.BinaryLabelDatasetMetric.base_rate)\n",
    "        * Method Parameters: **privileged** (bool, optional) – Boolean prescribing whether to condition this metric on the <code>privileged_groupsy</code>, if <code>True</code>, or the <code>unprivileged_groups</code>, if <code>False</code>. Defaults to <code>None</code> meaning this metric is computed over the entire dataset.\n",
    "\n",
    "**Disparate Impact Ratio**\n",
    "\n",
    "* References: \n",
    "    * [Feldman, Michael, et al. \"Certifying and removing disparate impact.\" 2015.](https://dl.acm.org/doi/abs/10.1145/2783258.2783311?casa_token=mgfTdMoZlmEAAAAA:X2WEkMRylcEdMPiqC7fvVM53uf7XfqbYyhHjZXfSF_FLrCITdhIURzGdCm3cxligj0-gcQUiAMpbLn0)\n",
    "    * [Towards Data Science Article](https://towardsdatascience.com/ai-fairness-explanation-of-disparate-impact-remover-ce0da59451f1)\n",
    "        * Disparate Impact is a metric to evaluate fairness. It compares the proportion of individuals that receive a positive output for two groups: an unprivileged group and a privileged group.\n",
    "        <br><br>\n",
    "        ![image-4.png](attachment:image-4.png)\n",
    "        <br><br>\n",
    "        The calculation is the proportion of the unprivileged group that received the positive outcome divided by the proportion of the privileged group that received the positive outcome. The industry standard is a \"4/5\" rule: if the unprivileged group receives a positive outcome less than 80% of their proportion of the privileged group, this is a disparate impact violation.\n",
    "\n",
    "**Smoothed Empirical Differential Fairness**\n",
    "\n",
    "* References:\n",
    "    * [J. R. Foulds, R. Islam, K. N. Keya, and S. Pan, “An Intersectional Definition of Fairness”, 2018](https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9101635)\n",
    "    * [IBM documentation 1](https://dataplatform.cloud.ibm.com/docs/content/wsj/model/wos-smooth-empirical-diff.html?context=cpdaas#:~:text=The%20calculation%20produces%20a%20value,Parent%20topic%3A%20Fairness%20metrics%20overview)\n",
    "    * [IBM documentation 2](https://www.ibm.com/docs/en/cloud-paks/cp-data/4.5.x?topic=tutorials-metrics-computation-using-python-sdk)\n",
    "        * The Smoothed Empirical Differential (SED) metric is used to quantify fairness in model predictions by comparing the differential of smoothed probabilities between different groups within a dataset. Specifically, it evaluates the minimum ratio of Dirichlet smoothed probabilities for favorable and unfavorable outcomes between intersecting groups divided by certain features within the dataset. These intersecting groups are considered equal, meaning there are no designated privileged or unprivileged groups. The SED metric value ranges between 0 and 1, with the value representing the aforementioned minimum ratio\n",
    "        * In terms of interpretation:\n",
    "            * A value of 1 would indicate perfect fairness, as it signifies that the ratio of favorable to unfavorable outcomes is the same across all intersecting groups.\n",
    "            * A value closer to 0 may indicate a disparity in the distribution of favorable and unfavorable outcomes among different intersecting groups, which could signify a lack of fairness.\n",
    "    \n",
    "    \n",
    "\n",
    "<br>"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "dataset_id = 0\n",
    "bins = 3\n",
    "dataset = fetch_openml(data_id=DATASETS[dataset_id], as_frame=True)\n",
    "print(dataset.target_names)\n",
    "df=dataset.data"
   ],
   "id": "6327aad0ecf763ff",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "fb262a66",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "def categorize_target(target):\n",
    "    if target<median:\n",
    "        return 0\n",
    "    if target >=median:\n",
    "        return 1\n",
    "    \n",
    "if dataset_id==0:\n",
    "    df.rename(columns={'MAR': 'Maritial status', 'RAC1P':'Race', 'AGEP':'Age', 'RELP':'Relationship', 'POBC':'Place of birth', 'SCHL':'School'}, inplace=True)\n",
    "    median = dataset.target.median()\n",
    "    dataset.target= dataset.target.apply(categorize_target)\n",
    "    \n",
    "\n",
    "if dataset_id==2:\n",
    "    dataset.target = dataset.target.replace('>30', 0)\n",
    "    dataset.target = dataset.target.replace('<30', 1)\n",
    "    dataset.target = dataset.target.replace('NO', 0)\n",
    "\n",
    "if dataset_id == 3:\n",
    "    dataset.data['ugpagt3'] = dataset.target\n",
    "    dataset.target = dataset.data[\"bar\"]\n",
    "    dataset.data.drop(columns=['bar'], inplace=True)\n",
    "    df= dataset.data\n",
    "    \n",
    "df = df.replace('nan', np.nan)\n",
    "df = df.dropna()       \n",
    "        \n",
    "df_copy = df.copy()\n",
    "for c in df_copy.columns:\n",
    "    df_copy[c] = df_copy[c].astype(str)\n",
    "    \n",
    "protected_attributes = list(fl.sensitive.detect_names_df(df_copy, deep_search=True).keys())\n",
    "print(\"Detected protected attributes: \", protected_attributes)\n",
    "if len(protected_attributes)==0:\n",
    "    raise Exception(\"No found possible protected attributes. Check the dataset or the naming of the attributes.\")\n",
    "\n",
    "for pa in protected_attributes:     \n",
    "    bins_age = 3\n",
    "    if pa.lower() == 'age' and df[pa].dtypes == 'int64':\n",
    "        df = df[df[pa] <= 100]\n",
    "        df[pa] = pd.qcut(df[pa], q=bins_age)\n",
    "        df[pa] = df[pa].astype('object')\n",
    "    \n",
    "    if df[pa].dtype == 'category':\n",
    "        df[pa] = df[pa].astype('object')\n",
    "        \n",
    "    if df[pa].dtype != 'object':        \n",
    "        if len(pd.unique(df[pa])) >= 10:\n",
    "            df[pa] = pd.cut(df[pa], bins=bins)\n",
    "        df[pa] = df[pa].astype('object')\n",
    "        \n",
    "for c in df.columns:\n",
    "    if (df[c].dtype == 'category'):\n",
    "        df[c] = df[c].astype('object')\n",
    "    elif (len(pd.unique(df[c])) <= 5):\n",
    "        df[c] = df[c].astype('object') \n",
    "        \n",
    "    if (df[c].dtype == 'int64' or df[c].dtype == 'float64') and (len(pd.unique(df[c])) > 20):\n",
    "        df[c] = pd.cut(df[c], bins=bins)\n",
    "        df[c] = df[c].astype('object')\n",
    "\n",
    "df.head()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "364149c7",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "## Sample Biases"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "affce707",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "### Data Normalization"
   ]
  },
  {
   "cell_type": "code",
   "id": "012a117f",
   "metadata": {},
   "source": [
    "# normalize the data\n",
    "numeric_data = df.select_dtypes(include=['int64', 'float64', 'uint8'])\n",
    "categorical_data = df.select_dtypes(include=['object', 'category'])\n",
    "try:\n",
    "    categorical_data[dataset.target_names[0]] = dataset.target\n",
    "except:\n",
    "    # that means that target attribute is the last column in a dataframe\n",
    "    pass\n",
    "    \n",
    "scaler = MinMaxScaler()\n",
    "scaled_data = []\n",
    "numerical_present = True\n",
    "if numeric_data.columns.size > 0:\n",
    "    scaled_data = scaler.fit_transform(numeric_data)\n",
    "    # no numerical data present in the dataset \n",
    "    numerical_present = False\n",
    "encoder = LabelEncoder()\n",
    "\n",
    "try:\n",
    "    encoded_data = categorical_data.apply(encoder.fit_transform)\n",
    "    encoded_data[encoded_data.columns.tolist()] = encoded_data[encoded_data.columns.tolist()].astype(object)\n",
    "    if numerical_present:\n",
    "          data = encoded_data.reset_index(drop=True)\n",
    "    else:\n",
    "        data = pd.concat([pd.DataFrame(scaled_data, columns=numeric_data.columns), encoded_data.reset_index(drop=True)], axis=1)\n",
    "    categorical_present = True\n",
    "except:\n",
    "    # no categorical attritbutes present in the observed dataset -> data = scaled numeric data\n",
    "    categorical_present = False\n",
    "    data = pd.DataFrame(scaled_data, columns=numeric_data.columns)\n",
    "\n",
    "data = data.drop_duplicates()\n",
    "data.head()\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "01211578",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "if categorical_present:\n",
    "    categorical_data = df.select_dtypes(include=['object', 'category'])\n",
    "    \n",
    "    try:\n",
    "        categorical_data[dataset.target_names[0]] = dataset.target\n",
    "    except:\n",
    "        # last column is the target label/attribute\n",
    "        pass\n",
    "\n",
    "    for c in categorical_data.columns:\n",
    "        le = LabelEncoder()\n",
    "        le.fit(categorical_data[c])\n",
    "        le_name_mapping = dict(zip(le.classes_, le.transform(le.classes_)))\n",
    "\n",
    "        print()\n",
    "        print('Attribute: ' + c)\n",
    "        print(le_name_mapping)\n",
    "else:\n",
    "    print('No categorical attributes found in the dataset!')"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "a1357ec0",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "### (Hidden) Correlation"
   ]
  },
  {
   "cell_type": "code",
   "id": "a1b2d0a1",
   "metadata": {
    "scrolled": false
   },
   "source": [
    "significance_matrix = {}\n",
    "correlation_matrix = pd.DataFrame(index=data.columns, columns=data.columns)\n",
    "for col1 in data.columns:\n",
    "    for col2 in data.columns:\n",
    "        if col1 != col2:\n",
    "            if (data[col1].dtype == object and data[col2].dtype == object):\n",
    "                # Chi2 test + Cramer's V test\n",
    "                contingency_table = pd.crosstab(data[col1], data[col2])\n",
    "                chi2, p, dof, expected = chi2_contingency(contingency_table)\n",
    "                \n",
    "                if (p < 0.05):\n",
    "                    cramers_v_value = association(contingency_table)\n",
    "                    correlation_matrix.at[col1, col2] = cramers_v_value\n",
    "                    significance_matrix[(col1, col2)] = p\n",
    "            elif ((data[col1].dtype == object and data[col2].dtype != object) or\n",
    "                  (data[col1].dtype != object and data[col2].dtype == object)):\n",
    "                if (data[col1].dtype == object):\n",
    "                    cat = data[col1]\n",
    "                    numeric = data[col2]\n",
    "                else:\n",
    "                    cat = data[col2]\n",
    "                    numeric = data[col1]\n",
    "                    \n",
    "                # One-Way ANOVA with effect size (multi-class categorical variable) -> omega squared effect size\n",
    "                if (len(pd.unique(cat)) > 2):\n",
    "                    q = data[[numeric.name, cat.name]]\n",
    "                    q[cat.name] = pd.to_numeric(q[cat.name])\n",
    "                    \n",
    "                    model = ols('Q(\\\"' + numeric.name + '\\\")' + ' ~ C(Q(\\\"' + cat.name + '\\\"))', data=q).fit()\n",
    "                    aov = sm.stats.anova_lm(model, typ=2)\n",
    "                    \n",
    "                    if (aov['PR(>F)'].iloc[0] < 0.05):\n",
    "                        aov['mean_sq'] = aov[:]['sum_sq']/aov[:]['df']\n",
    "                        aov['eta_sq'] = aov[:-1]['sum_sq']/sum(aov['sum_sq'])\n",
    "                        aov['omega_sq'] = (aov[:-1]['sum_sq']-(aov[:-1]['df']*aov['mean_sq'][-1]))/(sum(aov['sum_sq'])+aov['mean_sq'][-1])\n",
    "                        correlation_matrix.at[col1, col2] = aov['omega_sq'].iloc[0]\n",
    "                        significance_matrix[(col1, col2)] = aov['PR(>F)'].iloc[0]\n",
    "                else:\n",
    "                    # Point-Biserial (binary categorical variable)\n",
    "                    pointbiserial_corr, pointbiserial_p_value = pointbiserialr(cat, numeric)\n",
    "                    if (pointbiserial_p_value < 0.05):\n",
    "                        correlation_matrix.at[col1, col2] = pointbiserial_corr\n",
    "                        significance_matrix[(col1, col2)] = pointbiserial_p_value\n",
    "            else:                \n",
    "                # Pearson's correlation\n",
    "                coef, p_value = pearsonr(data[col1], data[col2])\n",
    "                if (p_value < 0.05):\n",
    "                    correlation_matrix.at[col1, col2] = coef\n",
    "                    significance_matrix[(col1, col2)] = p_value\n",
    "\n",
    "# Get the DataFrame index and columns\n",
    "index = correlation_matrix.index\n",
    "columns = correlation_matrix.columns\n",
    "\n",
    "# Extract elements below the main diagonal\n",
    "below_main_diagonal = correlation_matrix.where(np.tril(np.ones(correlation_matrix.shape), k=-1).astype(bool))\n",
    "\n",
    "# Set index and columns for the extracted matrix\n",
    "below_main_diagonal.index = index\n",
    "below_main_diagonal.columns = columns\n",
    "\n",
    "cmap = sns.diverging_palette(220, 20, as_cmap=True)\n",
    "mask = pd.isna(below_main_diagonal)\n",
    "\n",
    "# Create a heatmap using seaborn\n",
    "plt.figure(figsize=(15, 15))\n",
    "sns.heatmap(below_main_diagonal.fillna(0),\n",
    "            annot=True, \n",
    "            cmap=cmap, \n",
    "            center=0, \n",
    "            mask=mask,\n",
    "            vmin=below_main_diagonal.min().min(), \n",
    "            vmax=below_main_diagonal.max().max())\n",
    "plt.title('Correlation Heatmap\\n')\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "69c894f7",
   "metadata": {},
   "source": [
    "Omega square effect size calculation [source](https://www.pythonfordatascience.org/anova-python/#anova_statsmodels).\n",
    "\n",
    "Explanations why <b>omega squared</b> effect size is better than the <u>eta squared</u> can be found [here](https://www.theanalysisfactor.com/effect-size/) and [here](https://lbecker.uccs.edu/glm_effectsize) as well as in [this journal paper](https://psycnet.apa.org/record/2023-92087-001) in more details.\n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "id": "5ec13902",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "# siginificance matrix - dictionary holding all the significance tests results\n",
    "significance_matrix"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "cdf9adaf",
   "metadata": {},
   "source": [
    "q = below_main_diagonal.fillna(0).stack()\n",
    "\n",
    "top_largest = q.nlargest(15)\n",
    "top_smallest = q.nsmallest(5)\n",
    "\n",
    "candidates = pd.concat([top_largest, top_smallest])\n",
    "candidates = pd.DataFrame(candidates, columns=['corr'])\n",
    "candidates['abs_corr'] = abs(candidates['corr']) \n",
    "candidates = candidates.sort_values(by='abs_corr', ascending=False)\n",
    "candidates = candidates[candidates[\"corr\"] != 0]\n",
    "\n",
    "candidates = candidates['corr'].head(20)\n",
    "candidates"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "f63250c8",
   "metadata": {},
   "source": [
    "try:\n",
    "    exclude = list(protected_attributes) + [dataset.target_names[0]]\n",
    "except:\n",
    "    exclude = list(protected_attributes) + [data.columns[-1]]\n",
    "\n",
    "attribute_pairs = candidates.index.values.tolist()\n",
    "\n",
    "result = pd.Series()\n",
    "consumed_attributes = []\n",
    "for i, attribute_pair in enumerate(attribute_pairs):\n",
    "    att1 = attribute_pair[0]\n",
    "    att2 = attribute_pair[1]\n",
    "\n",
    "    if (att1 not in protected_attributes and att2 not in protected_attributes):\n",
    "        continue\n",
    "    if (att1 in exclude or att1 in consumed_attributes) and (att2 in exclude or att2 in consumed_attributes):\n",
    "        continue    \n",
    "    if (att1 not in exclude and att1 not in consumed_attributes):\n",
    "        consumed_attributes.append(att1)\n",
    "    if (att2 not in exclude and att2 not in consumed_attributes):\n",
    "        consumed_attributes.append(att2)\n",
    "\n",
    "    result = pd.concat([result, pd.Series(data={candidates.index[i]: candidates[i]})])\n",
    "\n",
    "result"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "significance_matrix[(\"fam_inc\", \"age\")]",
   "id": "a8a13f352b8e931e",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "0437cfea",
   "metadata": {
    "scrolled": false
   },
   "source": [
    "q = pd.unique(list(itertools.chain.from_iterable(result.index.values.tolist())))\n",
    "# attributes that are not sensitive but highly correlated with a sensitive attribute\n",
    "focus_attributes = [a for a in q if a not in exclude]\n",
    "print(focus_attributes)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "e36eb0d9",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "### Metrics Report"
   ]
  },
  {
   "cell_type": "code",
   "id": "a5ebeeee",
   "metadata": {
    "scrolled": false
   },
   "source": [
    "def calculate_entropy(series):\n",
    "    unique_values = pd.unique(series)\n",
    "    num_values = len(unique_values)\n",
    "    \n",
    "    if num_values == 1:\n",
    "        return 0  # If there's only one unique value, entropy is 0\n",
    "    \n",
    "    if series.dtype == np.number:\n",
    "        # Numerical attribute\n",
    "        sorted_values = np.sort(unique_values)\n",
    "        bins = [(sorted_values[i] + sorted_values[i+1]) / 2 for i in range(num_values - 1)]\n",
    "        hist, _ = np.histogram(series, bins=bins)\n",
    "        prob_distribution = hist / len(series)\n",
    "    else:\n",
    "        # Categorical attribute\n",
    "        value_counts = series.value_counts()\n",
    "        prob_distribution = value_counts / len(series)\n",
    "    \n",
    "    entropy_value = entropy(prob_distribution, base=num_values)\n",
    "    return entropy_value\n",
    "\n",
    "def calculate_imbalance_ratio(series):\n",
    "    if (series.dtype == object or series.dtype == 'category'):\n",
    "        # For both binary & multi-class categorical attributes (for multi-class the results are \"low-resolution\")\n",
    "        class_counts = series.value_counts()\n",
    "        return class_counts.max() / class_counts.min()\n",
    "    else:\n",
    "        return np.nan\n",
    "    \n",
    "def calculate_imbalance_degree(series, distance=\"EU\"):\n",
    "    if (series.dtype == object or series.dtype == 'category'):\n",
    "        return imbalance_degree(series, distance)\n",
    "    else:\n",
    "        return np.nan\n",
    "    \n",
    "def get_minority_classes(series):\n",
    "    \"\"\"\n",
    "    Minority classes are considered to be those with lower empirical_distribution \n",
    "    in comparisson to related attribute equiprobability\n",
    "    \"\"\"\n",
    "    if series.dtype == object or series.dtype == 'category':\n",
    "        unique_classes, class_counts = np.unique(series, return_counts=True)\n",
    "        empirical_distribution = class_counts / class_counts.sum()\n",
    "        \n",
    "        eqp = 1 / len(class_counts) # equiprobability\n",
    "        \n",
    "        result = {unique_classes[i]:x for i, x in enumerate(empirical_distribution) if x < eqp}\n",
    "        result = dict(sorted(result.items(), key=lambda item: item[1]))\n",
    "        return list(result.keys())\n",
    "    else:\n",
    "        return np.nan\n",
    "    \n",
    "def get_majority_classes(series):\n",
    "    \"\"\"\n",
    "    Majority classes are considered to be those with higher empirical_distribution \n",
    "    in comparisson to related attribute equiprobability\n",
    "    \"\"\"\n",
    "    if (series.dtype == object or series.dtype == 'category'):\n",
    "        unique_classes, class_counts = np.unique(series, return_counts=True)\n",
    "        empirical_distribution = class_counts / class_counts.sum()  \n",
    "        eqp = 1 / len(class_counts) # equiprobability\n",
    "        result = {unique_classes[i]:x for i, x in enumerate(empirical_distribution) if x > eqp}\n",
    "        result = dict(sorted(result.items(), key=lambda item: item[1], reverse=True))\n",
    "        return list(result.keys())        \n",
    "    else:\n",
    "        return np.nan\n",
    "    \n",
    "def get_attribute_label_encoder_mapping(attribute):\n",
    "    le = LabelEncoder()\n",
    "    le.fit(df[attribute])\n",
    "    return dict(zip(le.classes_, le.transform(le.classes_))) \n",
    "\n",
    "def detect_protected_attributes(dataframe):\n",
    "    stats = {}\n",
    "    concentrations = [10000, 5000, 1000, 100, 10, 1]\n",
    "    while(len(concentrations)):\n",
    "        exit = True\n",
    "        for attr in dataframe.columns:\n",
    "            entropy_val = calculate_entropy(dataframe[attr])\n",
    "            imbalance_ratio = calculate_imbalance_ratio(dataframe[attr])\n",
    "            imbalance_degree = calculate_imbalance_degree(dataframe[attr])\n",
    "            majority_classes = get_majority_classes(df[attr])   \n",
    "            minority_classes = get_minority_classes(df[attr])\n",
    "\n",
    "            base_rate_privileged = np.nan\n",
    "            base_rate_unprivileged_all = np.nan\n",
    "            disparate_impact_ratio_all = np.nan\n",
    "            base_rate_unprivileged_list = np.nan\n",
    "            disparate_impact_ratio_list = np.nan\n",
    "            if (dataframe[attr].dtype == object or dataframe[attr].dtype == 'category'):\n",
    "                label_names = dataset.target_names\n",
    "                if len(label_names) == 0:\n",
    "                    label_names = [data.columns[-1]]\n",
    "\n",
    "                bld = BinaryLabelDataset(\n",
    "                    df=data,\n",
    "                    label_names=label_names,\n",
    "                    protected_attribute_names=[attr],\n",
    "                    favorable_label=1,\n",
    "                    unfavorable_label=0)\n",
    "\n",
    "                le_name_mapping = get_attribute_label_encoder_mapping(attr)            \n",
    "                privileged_groups = [{attr: le_name_mapping[v]} for v in majority_classes]\n",
    "                unprivileged_groups = [{attr: le_name_mapping[v]} for v in minority_classes]\n",
    "\n",
    "                metric = BinaryLabelDatasetMetric(\n",
    "                        bld, \n",
    "                        privileged_groups=privileged_groups,\n",
    "                        unprivileged_groups=unprivileged_groups)\n",
    "\n",
    "                base_rate_privileged_all = metric.base_rate(True)\n",
    "                base_rate_unprivileged_all = metric.base_rate(False)\n",
    "                statistical_parrity_difference_all = metric.statistical_parity_difference()\n",
    "                disparate_impact_ratio_all = metric.disparate_impact()\n",
    "                sedf = metric.smoothed_empirical_differential_fairness(concentrations[-1])\n",
    "\n",
    "                if sedf > 1:\n",
    "                    exit = False\n",
    "                    concentrations.pop()\n",
    "                    break\n",
    "\n",
    "            if imbalance_degree is np.nan:\n",
    "                total_classes = np.nan\n",
    "            else:\n",
    "                total_classes = len(pd.unique(dataframe[attr]))\n",
    "\n",
    "            stats[attr] = {\n",
    "                'majority_classes': majority_classes,\n",
    "                'minority_classes': minority_classes,\n",
    "                'total_classes': total_classes,\n",
    "                'entropy': entropy_val,\n",
    "                'imbalance_ratio': imbalance_ratio,\n",
    "                'imbalance_degree': imbalance_degree,\n",
    "                'statistical_parity_difference': statistical_parrity_difference_all,\n",
    "                'disparate_impact_ratio': disparate_impact_ratio_all,\n",
    "                'smoothed_edf': sedf\n",
    "            }\n",
    "        \n",
    "        if exit:\n",
    "            break\n",
    "            \n",
    "    print('Concentration parameter for Dirichlet smoothing: ' + str(concentrations[-1]))\n",
    "    return pd.DataFrame(stats).transpose()\n",
    "\n",
    "focus = protected_attributes + focus_attributes\n",
    "print(focus)\n",
    "stats = detect_protected_attributes(data[focus])\n",
    "stats"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "8a7de722",
   "metadata": {},
   "source": [
    "yes<br>\n",
    "\n",
    "<u>Interpretation of **entropy** values in the context of fairness:</u>\n",
    "* Source: [Information Entropy (Medium article)](https://medium.com/@mhannan94/information-entropy-3cce2bac62a2)\n",
    "    * Entropy is a measure of how much information a variable contains. When a low probability event occurs, it carries more information (“surprisal”) and a high probability event carries less information, because we are not as surprised that the event occurred. If a variable can only take a single value, the entropy of said variable is 0, because we know with complete certainty what value the variable will take. \n",
    "\n",
    "<u>Interpretation of **imbalanced degree (ID)** values (summary section from J. Ortigosa-Hernández et al. 2017):</u>\n",
    "    \n",
    "* (i) it is a single easy-readable real value in the range [0, K), where K is the number of classes\n",
    "\n",
    "* (i+) For multi-class categorical variables the **equiprobability** value is important which says which of the labels are categorized as majority one and which as minority\n",
    "\n",
    "* (ii) Empirical results show that imbalance-degree has a higher resolution and is more sensitive to express the hindrance that skewed class distributions cause in the traditional supervised algorithms than imbalance-ratio\n",
    "\n",
    "        \n",
    "<u>Interpretation of **imbalance degree** values in the context of fairness:</u>\n",
    "    \n",
    "In many cases, a higher imbalance degree can signal potential fairness or bias issues, but the interpretation can vary depending on the specific context. Here's how you can relate imbalance degree to fairness:\n",
    "\n",
    "* High Imbalance Degree:\n",
    "    * A higher imbalance degree typically indicates a significant disparity in the distribution of outcomes or attributes. In the context of fairness, this could mean that a particular group or category is disproportionately affected by certain outcomes, such as positive or negative outcomes. If the attribute with a high imbalance degree is a protected attribute (e.g., gender, race), it may indicate potential bias or discrimination in the system. For example, if one gender is much more likely to receive a certain outcome, this could be a sign of gender bias.\n",
    "    \n",
    "* Low Imbalance Degree:\n",
    "    * A lower imbalance degree suggests a more balanced distribution of outcomes or attributes. In the context of fairness, this can indicate a fairer system where different groups or categories are more equally treated. However, it's important to note that low imbalance degree does not necessarily guarantee fairness. There can still be other forms of bias or fairness issues that are not captured by this measure.\n",
    "\n",
    "* Interpretation Depends on Context:\n",
    "    * The interpretation of imbalance degree always depends on the specific context and what you consider a fair or unbiased distribution. In some cases, a certain level of imbalance may be acceptable or even desirable if it reflects underlying differences in the population. To assess fairness comprehensively, you should consider various fairness metrics, domain-specific knowledge, and social, legal, and ethical considerations. It's not solely about the imbalance degree but also about the implications of that imbalance on different groups and individuals."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0033a2a8",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "### Metrics Ranking"
   ]
  },
  {
   "cell_type": "code",
   "id": "feffae1f",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "# \"higher is better\" in the context how sensitive an attribute actually is \n",
    "# ranking score   -> the least sensitive attribute gets the best score (e.g., 1) for observed metric\n",
    "# ranking overall -> the most sensitive attribute will have the highest sum of ranking scores, while\n",
    "#                    the least sensitive the lowest sum of ranking scores\n",
    "higher_is_better = {\n",
    "    'entropy': True,                           # the higher the entropy, the less sensitive an attribute is\n",
    "    'imbalance_ratio': False,                  # the higher the imbalance ratio, the more sensitive an attribute is\n",
    "    'imbalance_degree': False,                 # the higher the imbalance degree, the more sensitive an attribute is\n",
    "    'statistical_parity_difference': False,    # the higher the (absolute) statistical parity difference, the more sensitive an attribute is\n",
    "    'disparate_impact_ratio': False,           # the higher the difference (\"DIR - 1\" observation), the more sensitive an attribute is (difference of 0 would indicate perfect fairness)\n",
    "    'smoothed_edf': True                       # the higher the smoothed EDF, the less sensitive an attribute (value of 1 would indicate perfect fairness)\n",
    "}\n",
    "\n",
    "def calculate_rank(values):\n",
    "    sorted_values = values.sort_values(ascending=not higher_is_better[metric])\n",
    "    ranks = sorted_values.rank(method='dense', ascending=not higher_is_better[metric])\n",
    "    return ranks\n",
    "\n",
    "ranks = stats[stats.columns[3:]]\n",
    "\n",
    "for metric in ranks.columns:\n",
    "    if metric == 'disparate_impact_ratio':\n",
    "        ranks[metric] = calculate_rank(abs(ranks[metric] - 1))\n",
    "    elif metric == 'imbalance_degree':\n",
    "        ranks[metric] = calculate_rank(ranks[metric] / stats['total_classes'])\n",
    "    elif metric == 'statistical_parity_difference':\n",
    "        ranks[metric] = calculate_rank(abs(ranks[metric]))\n",
    "    else:\n",
    "        ranks[metric] = calculate_rank(ranks[metric])\n",
    "        \n",
    "ranks = ranks.astype(int)\n",
    "ranks"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "c547340f",
   "metadata": {},
   "source": [
    "distribution_metrics = ['entropy', 'imbalance_ratio', 'imbalance_degree']\n",
    "aif360_metrics = ['statistical_parity_difference', 'disparate_impact_ratio', 'smoothed_edf']\n",
    "\n",
    "dist_rankings = pd.DataFrame(ranks[distribution_metrics].sum(axis=1).sort_values(ascending=False), columns=['RS*'])\n",
    "dist_rankings['R*'] = list(range(1, len(dist_rankings) + 1))\n",
    "\n",
    "aif360_rankings = pd.DataFrame(ranks[aif360_metrics].sum(axis=1).sort_values(ascending=False), columns=['RS**'])\n",
    "aif360_rankings['R**'] = list(range(1, len(aif360_rankings) + 1))\n",
    "\n",
    "rankings_all = pd.DataFrame(ranks.sum(axis=1).sort_values(ascending=False), columns=['RS'])\n",
    "rankings_all['R'] = list(range(1, len(rankings_all) + 1))\n",
    "\n",
    "dataset_rankings = dist_rankings.join(aif360_rankings)\n",
    "dataset_rankings = dataset_rankings.join(rankings_all)\n",
    "dataset_rankings = dataset_rankings.sort_values(by='R')\n",
    "\n",
    "print('Legend:')\n",
    "print('------------------------------')\n",
    "print('RS* = Total Ranking Score for ranking scores which include only \\'distribution\\' metrics')\n",
    "print('      (e.g., entropy, IR & ID)')\n",
    "print('R* = Ranking based on total ranking scores coming only from \\'distribution\\' metrics')\n",
    "print('      (e.g., entropy, IR & ID)')\n",
    "print()\n",
    "print('RS** = Total Ranking Score for ranking scores which include only \\'AIF360\\' metrics')\n",
    "print('      (e.g., SPD, DIR & SEDF)')\n",
    "print('R** = Ranking based on total ranking scores coming only from \\'AIF360\\' metrics')\n",
    "print('      (e.g., SPD, DIR & SEDF)')\n",
    "print()\n",
    "print('RS = Total Ranking Score for ALL ranking scores')\n",
    "print('R = Ranking based on total ranking scores coming from ALL metrics')\n",
    "\n",
    "dataset_rankings"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "93675834",
   "metadata": {},
   "source": "DRANKINGS= stats.join(dataset_rankings).sort_values(by='R')",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "DRANKINGS",
   "id": "3fb8ae995f491176",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
